---
title: "Technical Report: Predicting Yelp Price Ranges"
author: "Josh Dey, Emmett Powers, & Giorlando Ramirez"
date: "12/10/2019"
output: pdf_document
---

***

# Abstract
In this project, we leverage a large Yelp data set comprised of about 200k observations in order to build a predictive model of restaurant prices. We go about answering this question deploying three supervised learning models: linear regression, ordinal regression, and classification trees. We find that the available variables have fairly limited predictive power across our models.

### Preparing Libraries
```{r}
library(ggplot2)
library(Amelia)
library(rlist)
library(dplyr)
library(tidyverse)
library(jsonlite)
library(rcompanion)
library(MASS)
```


# Introduction
In this project we want to use a large dataset provided by Yelp to predict restaurant prices. Economic intuition would have it that there are certain things restaurants might sell and/or provide that would make them more or less expensive, a prime example being the sale of alcohol. Thus, with this project we wish to put this intuition to the test. The Yelp dataset is comprised of many individual restaurant observations with variables that are likely determinants of the restaurants prices, such as whether they provide outdoor seating or the expected attire, so with this data we go about building a variety of models which might predict a given restaurant's price range.


# The Data
The data used in this project comes from the Yelp Open Dataset. This is a massive dataset Yelp releases for educational purposes, which is comprised of three main sub datasets: reviews, business, and images. In this project we use the business dataset, a dataset which contains a variety of descriptive variables for 192,609 business location. However, in this project we're focused specifically on restaurants, so when we trim the data to only include restaurants we end up with 59,371 total observations. Each observation is a given restaurant with all of the associated variables, from name of the restaurant, star rating through whether the restaurant serves alcohol. There are a total of 53 variables.

In order to perform any meaningful analysis we needed to clean the data. Thus, as mentioned previously, we began this process by cutting the data to only include restaurants. This resulted in a total of 59,371 observations. We then filtered the data set to only include predictor variables we believed would have the strongest predictive capability- such as: # of stars, whether the restaurant served alcohol, etc.- and proceeded to further cut the data to only include observations which were complete (included an observation for every variable). This resulted in a dataset with 40,584 observations, a loss of about 30% of original observations. We have no reason to believe there exist systematic reasons as to why restaurants would omit data on these variables, and thus chose this as our final dataset, which we use to perform our analysis and create our models.


# Exploratory Data Analysis
Explore the structure of the data through graphics. Here you can utilize both traditional plots as well as methods from unsupervised learning. Understanding the distribution of your response is particular important, but also investigate bivariate and higher-order relationships that you expect to be particular interesting.

In this section we look over the data in order to identify trends, concerns, and other consideration we might need to take into account when creating our models.

### Initial Data Prep
First, we load up the data before we begin our exploratory analysis. 
We also filter the data for the explanatory variables we wish to use.

```{r}
business <- stream_in(file("business.json"))
clean.business <- business

## Filtering for restaurants
clean.business$Restaurant <- 0 
new.business <- mutate(clean.business, Restaurant=grepl("Restaurants", clean.business$categories))
restaurants <- filter(new.business, Restaurant == "TRUE")

## Isolating the important variables
attribute <- restaurants$attributes
restaurant_data <- restaurants
restaurant_data$attributes <- NULL
restaurant_data$Restaurant <- NULL
restaurant_data <- cbind(restaurant_data, attribute)
voi <- c("name", "city", "state", "latitude", "longitude", "stars", "review_count", "RestaurantsTakeOut", 
         "RestaurantsPriceRange2", "OutdoorSeating", "Alcohol", "categories", "RestaurantsAttire")
rdata <- subset(restaurant_data, select=voi)
```

## Missingness
Now we look at the missingness in the data, and we decouple it into response and some predictor variables.

```{r, cache = TRUE}
## Missingness when including all of the restaurant observations
missmap(rdata)

## Missingness in the response
prices <- data.frame(rdata$RestaurantsPriceRange2)
missmap(prices)

## Missingness in the explanatory variables
alcohol <- data.frame(rdata$Alcohol)
outdoorseating <- data.frame(rdata$OutdoorSeating)
dresscode <- data.frame(rdata$RestaurantsAttire)
missmap(outdoorseating)
missmap(alcohol)
missmap(dresscode)
```

The missingness maps reveal that though our overall missingness is minimal, there are a couple things worth noting. In terms of the response variable, it is only 12% which is not too concerning since we still have a value for the major of observations. Further, we notice that the missingness is concentrated around the more niche variables, which are the determinants of the price range. This would be an issue if we considered there to exist a systematic issue in the missingness occurring, however we do not think this is the case. We believe the missingness is randomly distributed, so we assume it is not problematic to simply get rid of observations which do not have values for all of our variables. Thus, the final data we use will contain only complete observations. Now that we have a cursory look at the overall data and know that we will get rid of incomplete observations, we turn to preparing it for a survey of the response and predictive variables.

## Preparing Data
```{r}
##Cleaning Data to only include complete observations
rdata.clean <- rdata[complete.cases(rdata),]

## Fixing Variables
rdata.clean$OutdoorSeating <- as.logical(rdata.clean$OutdoorSeating)
rdata.clean$OutdoorSeating <- as.numeric(rdata.clean$OutdoorSeating)

rdata.clean$RestaurantsTakeOut <- as.logical(rdata.clean$RestaurantsTakeOut)
rdata.clean$RestaurantsTakeOut <- as.numeric(rdata.clean$RestaurantsTakeOut)

#Assigning categorical levels 1, 2, or 3 for alcohol
rdata.clean$Alc <- 0 
lvlone <- c("'none'", "u'none'")
lvltwo <- c("'beer_and_wine'", "u'beer_and_wine'")
lvlthree <- c( "'full_bar'", "u'full_bar'")
rdata.clean$Alc <- ordered(rdata.clean$Alcohol, levels = c(lvlone, lvltwo, lvlthree))
rdata.clean$Alc <- as.numeric(rdata.clean$Alc)
rdata.clean$Alc[rdata.clean$Alc == 2] <- 1
rdata.clean$Alc[rdata.clean$Alc == 3] <- 2
rdata.clean$Alc[rdata.clean$Alc == 4] <- 2
rdata.clean$Alc[rdata.clean$Alc == 5] <- 3
rdata.clean$Alc[rdata.clean$Alc == 6] <- 3
# rdata.clean$Alc <- as.factor(rdata.clean$Alc)

# Doing the same for Attire; had to do it differently for some reason
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "'casual'"] <- 1
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "u'casual'"] <- 1
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "'dressy'"] <- 2
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "u'dressy'"] <- 2
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "'formal'"] <- 3
rdata.clean$RestaurantsAttire[rdata.clean$RestaurantsAttire == "u'formal'"] <- 3
# rdata.clean$RestaurantsAttire <- as.factor(rdata.clean$RestaurantsAttire)

rdata.cleaner <- na.omit(rdata.clean)
d1 <- rdata.cleaner[c(-1 , -2, -3, -11, -12 )]
d1 <- d1 %>% rename(Takeout = RestaurantsTakeOut, PriceRange = RestaurantsPriceRange2, Attire = RestaurantsAttire)
d1$Attire[d1$Attire == "None"] <- 1
d1$PriceRange[d1$PriceRange == "None"] <- NA
d1 <- na.omit(d1)

```

Now we have d1, our final data set which we use to analyze the response & predictor variables, as well as for the construction of our models.

## Response Variable Analysis
```{r}
d1$PriceRange <- as.numeric(d1$PriceRange)
ggplot(d1, aes(x=PriceRange)) + 
  geom_histogram(color="black", fill="white") +
  xlab("Restaurant Rrice Range (# of $)") +
  ylab("Number of Restaurants in Range")
```

Here we see that our response variable (the price range) is heavily right skewed, with a large concentration of observations around 2 (about 53%). This is worth noting, as we might need to address it in our model construction.

## Predictors
```{r}
## Numerical 
ggplot(d1, aes(x=stars)) + 
  geom_histogram(color="black", fill="white")

ggplot(d1, aes(x=review_count)) + 
  geom_histogram(color="black", fill="white")

## Categorical
ggplot(d1, aes(x=Attire)) + 
  geom_bar(color="black", fill="white")

ggplot(d1, aes(x=Takeout)) + 
  geom_bar()

ggplot(d1, aes(x=OutdoorSeating)) + 
  geom_bar()

ggplot(d1, aes(x=Alc)) + 
  geom_bar()
```

### Numerical
There are a couple of interesting things about our predictive variables. The stars variable has a slightly left skewed distribution, with most restaurants falling under the 3.5 - 4 star rating. Review count appears to be centered around a couple of reviews, with very major outliers. 

### Categorical
It is difficult to make any meaningful assertions from a cursory look at the categorical, however there are a few things worth noting. Attire is heavily concetrated around the first category, "casual", which is intuitive since most restaurants are casual walk-in locations. Take out is also very heavily concentrated around 1 (which means they do Take Out), which is again intuitive since we'd expect most places to do take out. Outdoor seating has a fairly even split, though there are a larger number of restaurants that do not have it available. And alcohol has a similar amount under the categories of no alcohol & full bar, with a fairly smaller number under "beer and wine".

# Modeling

## Descriptive Classification Tree 
```{r}
library(rpart)
library(rpart.plot)
d1$PriceRange <- as.factor(d1$PriceRange)
m1 <- rpart(PriceRange ~. , data = d1,
  control = rpart.control(minsplit = 2))
plot1<-prp(m1)

```

## Preparing the Data: Training and Test

Before building our supervised learning models, we must first create our training and test sub datasets.

```{r}

s.size <- floor(0.75 * nrow(d1))
set.seed(10)
train.data <- sample(seq_len(nrow(d1)), size = s.size)
train <- d1[train.data, ]
test <- d1[-train.data, ]
```

## Linear Model

Though this is a classification exercise, the first model we developed was a linear model with rounding, as follows:

```{r}
d1$PriceRange <- as.numeric(d1$PriceRange)
m2 <- lm(PriceRange ~.,  data = train)

## Predicting Price
predicted.price <- predict(m2, newdata = test)
predicted.price.rounded <- round(predicted.price, digits = 0)
yp <- predicted.price.rounded

## Misclassification rate:
yt <- test$PriceRange

mcr2 <- table(yp,yt)

1-sum(diag(mcr2))/sum(mcr2)
```

A couple of things are worth noting about our process in building this model. First, we aimed to address the issue around the right skewedness of the data by performing some transformations. However, none of these changes significantly improved the predictive strength of the model, thus we chose to not keep any of the transformations. Regarding the explanatory variables we chose, we also tried a variety of models with different variables and opted to choose this one.

With this model we find a misclassification rate of 27.52%. While this modeling method is not necessarily made for this exercise, it is quite robust since it identifies just over 70% of restaurant price ranges correctly. However, we wished to further develop our understanding of the relationship between restaurant prices and the variables, so we continue our explorations with an Ordinal Regression, which should more aptly tackle the classification nature of this problem.

## Ordinal Regression

```{r}
class <- ordered(d1$PriceRange, levels= c("1", "2", "3", "4")) 
d1$class <- class
set.seed(20)
olr.train.data <- sample(seq_len(nrow(d1)), size = s.size)
olr.train <- d1[olr.train.data, ]
olr.test <- d1[-olr.train.data, ]
olr.train$PriceRange = NULL
olr.test$PriceRange = NULL

m3 <- polr(class ~. ,  data = olr.train,  Hess = TRUE) 
m3
predicted.price3 <- predict(m3, newdata = olr.test)
predicted.price3
# misclassification rate: 
yp2 <- predicted.price3
yt2 <- olr.test$class
mcr2 <- table(yp2,yt2)
1-sum(diag(mcr2))/sum(mcr2)

```



# Discussion
The variables provided to us with the data set from Yelp included: the name of the business, city, state, latitude, longitude, stars, review count, whether they do take out or not, the price range, whether or not they offer outdoor seating, whether or not they have a full bar inside, the category that the business falls into, and the attire of the restaurant. From this data set, we decided to try and create a model that predicted the price range of the restaurant; i.e, the number of dollar signs displayed on Yelp. We attempted to model this potential relationship with a linear regression (both with and without rounding due to only integer number of dollar signs), ordinal regression, and classification trees. From this data, we decided to use the numerical variables: latitude, longitude, number of stars, and review count; as well as the qualitative variables: alcohol, attire, outdoor seating, and takeout. We found that our qualitative variables (such as stars, alcohol,attire) were fairly strong predictors of price range.

Using a linear model with rounding we were able to obtain a misclassification rate of 27.62%. Using the ordinal regression model, we were able to obtain a misclassification rate just slightly better than the linear model: a misclassification rate of 27.5%. Both these models are somewhat accurate as just guessing 2$ for each restaurant would yield roughly a 50% accuracy rate, and both these models would be 22.38% and 22.5% more accurate, respectively. However, both of these models could be improved upon with the addition of more variables, perhaps from the entirety of Yelp’s dataset. 

Our classification tree using only numerical variables resulted in all branches ending in a 1 or 2, not surprising since the bulk of the restaurants in the data are rated as 1 or 2 dollar signs. However, utilizing the qualitative predictors show that they are more important as the result in a single branch ending in a 3.

Future research into this model may consider utilizing more variables from the Yelp data set that were omitted from this analysis due to missingness or lack of theoretical support, and might also incorporate the actual text reviews into the prediction. Our model controls for variations in price ranges across the 10 geographical areas, so we do not believe that the addition of new metropolitan areas would make the models more robust, since we assume that the price distribution that exists with these 10 would extend to any additional metro areas. Considering some unsupervised techniques, like PCA, may also be helpful in generating the model. It may also help to explore whether the type of restaurant (whether it be Chinese food or a steakhouse) affects the price range as it does seem like a potential indicator. The drawback of using this data set was that it characterized each restaurant as different types and not a single characteristic. It may also be worthwhile to see whether or not the variable we included effect the number of stars that a restaurant has on Yelp.


# References

“Yelp Open Dataset.” Yelp Dataset, 2019, www.yelp.com/dataset.
