---
ztitle: "DataVisualization"
author: "Giorlando Ramirez"
date: "12/8/2019"
output: pdf_document
---

Preparing Data:
```{r}
library(rlist)
library(dplyr)
library(tidyverse)
library(jsonlite)

#business <- stream_in(file("business.json"))
clean.business <- business

## Filtering for restaurants
clean.business$Restaurant <- 0 
new.business <- mutate(clean.business, Restaurant=grepl("Restaurants", clean.business$categories))
restaurants <- filter(new.business, Restaurant == "TRUE")

## Isolating the important variables
attribute <- restaurants$attributes
restaurant_data <- restaurants
restaurant_data$attributes <- NULL
restaurant_data$Restaurant <- NULL
restaurant_data <- cbind(restaurant_data, attribute)
voi <- c("name", "city", "state", "latitude", "longitude", "stars", "review_count", "RestaurantsTakeOut", 
         "RestaurantsPriceRange2", "OutdoorSeating", "Alcohol", "categories", "RestaurantsAttire")
rdata <- subset(restaurant_data, select=voi)

##Cleaning Data to only include complete observations
rdata.clean <- rdata[complete.cases(rdata),]

## Fixing Variables
rdata.clean$OutdoorSeating <- as.logical(rdata.clean$OutdoorSeating)
rdata.clean$OutdoorSeating <- as.numeric(rdata.clean$OutdoorSeating)

rdata.clean$RestaurantsTakeOut <- as.logical(rdata.clean$RestaurantsTakeOut)
rdata.clean$RestaurantsTakeOut <- as.numeric(rdata.clean$RestaurantsTakeOut)

#Assigning categorical levels 1, 2, or 3 for alcohol
rdata.clean$Alc <- 0 
lvlone <- c("'none'", "u'none'")
lvltwo <- c("'beer_and_wine'", "u'beer_and_wine'")
lvlthree <- c( "'full_bar'", "u'full_bar'")
rdata.clean$Alc <- ordered(rdata.clean$Alcohol, levels = lvlone, lvltwo, lvlthree)
rdata.clean$Alc <- as.numeric(rdata.clean$Alc)
rdata.clean$Alc <- rdata.clean$Alc %>% replace_na(3)
```

Subsetting train and test data: 
```{r}
library(tidyverse)
#class <- ordered(rdata.clean$RestaurantsPriceRange2, levels= c("1", "2", "3", "4")) 
#rdata.clean$class <- class
s.size <- floor(0.75 * nrow(rdata.clean))
set.seed(10)
train.data <- sample(seq_len(nrow(rdata.clean)), size = s.size)
train <- rdata.clean[train.data, ]
test <- rdata.clean[-train.data, ]
```

LM 
```{r}
library(rcompanion)

lm.train <- train[complete.cases(train),]
lm.train$RestaurantsPriceRange2 <- as.numeric(lm.train$RestaurantsPriceRange2)
lm.train$RestaurantsPriceRange2 <- lm.train$RestaurantsPriceRange2
lin.mod <- lm(RestaurantsPriceRange2 ~ stars + review_count + latitude + 
                longitude + RestaurantsAttire +
                RestaurantsTakeOut + OutdoorSeating + Alcohol,  data = lm.train)

#Predicting Price
predicted.price <- predict(lin.mod, newdata = test)
predicted.price.rounded <- round(predicted.price, digits = 0)
yt <- test$RestaurantsPriceRange2

# Misclassification rate: 

## Rounding Model
table_2 <- data.frame(predicted.price.rounded, yt)
mcr2 <- table(predicted.price.rounded,yt)
1-sum(diag(mcr2))/sum(mcr2)
ggplot(table_2, aes(x=yt, y=predicted.price.rounded)) + 
  geom_point()+
  labs(title="Predicted v Actual: Linear Model (W/ Rounding)",
       x="Actual Price Range", y = "Predicted Price Range") +
  theme_classic()

## Linear Model w/o rounding
yp <- predicted.price.rounded
yt <- test$RestaurantsPriceRange2

table <- data.frame(yp,yt)
mcr.table <- table(yp,yt)

1-sum(diag(mcr.table))/sum(mcr.table)
ggplot(table, aes(x=yt, y=yp)) + 
  geom_point()+
  labs(title="Predicted v Actual: Linear Model",
       x="Actual Price Range", y = "Predicted Price Range") +
  theme_classic()

```


Map
```{r}
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(ggplot2)
library(maps)
library(tools)

world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))


ggplot(data = world) +
    geom_sf(data = states, fill = NA) +
    geom_point(data = rdata.clean, aes( x = longitude, y = latitude), size = 3, shape = 23, fill = "blue") +
  coord_sf(xlim = c(-130, -60), ylim = c(23, 54), expand = FALSE) +
  labs(title="Restaurant Data Mapped",
       x="Longitude", y = "Latitude")
```

# Introduction
Overview of the setting of the data, existing theories/models (particularly if you are working in a descriptive/inferential setting), and your research questions.

In this project we want to use a large dataset provided by Yelp to predict restaurant prices. Economic intuition would have it that there are certain things restaurants might sell and/or provide that would make them more or less expensive, a prime example being the sale of alcohol. Thus, with this project we wish to put this intuition to the test. The Yelp dataset is comprised of many individual restaurant observations with variables that are likely determinants of the restaurants prices, such as whether they provide outdoor seating or the expected attire, so with this data we go about building a variety of models which might predict a given restaurant's price range.
